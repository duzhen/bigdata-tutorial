{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigdata-LA2 tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spark DataFrame API\n",
    "### SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"bigdata-LA2\") \\\n",
    "    .getOrCreate()\n",
    "print(\"spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(0, 0, 4.0), (0, 1, 2.0), (1, 1, 3.0), \\\n",
    "                            (1, 2, 4.0), (2, 1, 1.0), (2, 2, 5.0)], \\\n",
    "                           [\"user\", \"item\", \"rating\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average rating\n",
    "mean = df.select(\"rating\").groupBy().avg().take(1)[0][0]\n",
    "print(mean)\n",
    "\n",
    "# get average rating by user\n",
    "user_mean = df.groupBy(\"user\").avg(\"rating\").withColumnRenamed(\"avg(rating)\", \"user-mean\")\n",
    "user_mean.show()\n",
    "\n",
    "# get average rating by item\n",
    "item_mean = df.groupBy(\"item\").avg(\"rating\").withColumnRenamed(\"avg(rating)\", \"item-mean\")\n",
    "item_mean.show()\n",
    "\n",
    "def get_bias(df):\n",
    "    df = df.join(user_mean, \"user\").join(item_mean, \"item\")\n",
    "    return df.withColumn(\"bias\", df.rating-(df[\"user-mean\"]+df[\"item-mean\"]-mean))\n",
    "\n",
    "# add new column bias rating\n",
    "bias_df = get_bias(df)\n",
    "bias_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recommender systems\n",
    "\n",
    "[Collaborative Filtering](http://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.createDataFrame([(0, 2, 3.0), (1, 0, 3.0), (2, 0, 3.0)], \\\n",
    "                           [\"user\", \"item\", \"rating\"])\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(rank=10, maxIter=5, seed=0)\n",
    "model = als.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "predictions = model.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_bias(test)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(rank=10, maxIter=5, seed=0, ratingCol=\"bias\")\n",
    "model = als.fit(bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "predictions = model.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by the final rating\n",
    "predictions_final = predictions.withColumn(\"final_ratings\", predictions[\"user-mean\"]+predictions[\"item-mean\"]-mean+predictions[\"prediction\"])\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"final_ratings\")\n",
    "rmse = evaluator.evaluate(predictions_final)\n",
    "predictions_final.show()\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ALS Python docs](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
